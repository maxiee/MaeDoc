---
name: hardness-classify
description: 对当前问题进行硬度评估，判断是否超出本地模型独立处理的置信范围，若超出则自动生成自给自足的外部求助包并写入 .docforge/outbox/
---

# hardness-classify

> **Skill ID**：`hardness-classify`
> **版本**：1.0.0
> **类型**：instruction
> **用途**：在尝试回答复杂问题前，先评估其硬度；若超出阈值，自动打包上下文并生成外部求助文件

---

## 触发方式

本 Skill 有两种触发方式：

1. **AI 主动调用**（推荐）：在检测到 AGENTS.md §8.1 的任一触发条件后，于正式回答前调用本 Skill
2. **用户显式调用**：用户说"做一下硬度评估"、"判断这个问题是否需要外部求助"

---

## 输入

| 参数 | 必需 | 说明 |
|------|:----:|------|
| `question` | 是 | 待评估的问题或决策点 |
| `context_summary` | 否 | 本次会话的背景摘要（任务目标、已读文档等） |
| `ai_analysis` | 否 | AI 目前的分析思路和卡住的地方 |
| `related_docs` | 否 | 与问题相关的文档路径列表 |

若由 AI 主动调用，上述参数均由 AI 从当前对话上下文中自动提取，无需用户提供。

---

## 执行步骤

### 步骤 1：硬度评估

对 `question` 进行以下六个维度的评分（每项 0-2 分）：

| 维度 | 0 分 | 1 分 | 2 分 |
|------|------|------|------|
| **H1 置信度** | AI 有高置信答案 | 有答案但有明显不确定性 | 无法给出可靠答案 |
| **H2 方案博弈** | 方案唯一或优劣明确 | 有多方案但可分析权衡 | 多方案相互矛盾无法裁决 |
| **H3 专业知识** | 通用知识可覆盖 | 需要特定领域知识 | 需要深度专业判断 |
| **H4 论证盲点** | 推理路径完整清晰 | 有某些盲点但可标注 | 盲点可能导致系统性偏差 |
| **H5 决策代价** | 错误代价低，可迭代 | 错误代价中等 | 错误代价高，影响后续大量工作 |
| **H6 信息缺口** | 所需信息完整 | 有部分缺失但可推断 | 关键信息缺失无法弥补 |

**计算总分**（0-12 分）并确定等级：

| 总分 | 等级 | 建议 |
|------|------|------|
| 0-3 | 🟢 **LOW**（可独立处理） | 正常回答，标注 [HIGH] 或 [MED] |
| 4-6 | 🟡 **MEDIUM**（建议部分求助） | 回答已知部分，对不确定部分建议求助 |
| 7-12 | 🔴 **HIGH**（必须求助） | 停止尝试回答，执行主动上报流程 |

---

### 步骤 2：输出评估报告（简洁）

无论结果如何，先用 2-4 行输出评估结论：

```
硬度评估：[等级图标] [等级名称]（总分 {N}/12）
主要原因：[1-2句说明最高分的维度及其原因]
建议：[CONTINUE 继续回答 / PARTIAL 部分回答 + 标注 / ESCALATE 主动上报]
```

---

### 步骤 3：若等级为 HIGH，执行主动上报

> 若等级为 LOW 或 MEDIUM，跳过本步骤，返回正常回答流程。

#### 步骤 3.1：收集上下文

从当前对话和文件系统中收集以下信息：

**3.1.1 项目背景**
- 读取 `docs/index.md`（若存在），提取项目概览
- 从 AGENTS.md §1 提取项目介绍（已在系统提示中，直接引用）

**3.1.2 当前任务**
- 从对话历史中提炼：用户最终想完成什么？当前处于哪个阶段？

**3.1.3 相关文档内容**
- 读取 `related_docs` 中列出的所有文件
- 若未指定，根据问题内容判断最相关的文档并读取（最多 3 个）
- 将文档全文（或关键章节）纳入上报包

**3.1.4 AI 的分析过程**
- 整理 `ai_analysis`（若未提供，由 AI 根据当前认知自行补充）
- 包括：已考虑的角度、发现的矛盾、不确定的原因

**3.1.5 已知约束**
- 从对话上下文中提取：技术限制、用户偏好、项目规范、明确的排除项

#### 步骤 3.2：生成文件名

- 从 `question` 中提取核心关键词（2-4个词），转为 kebab-case 英文
- 执行 `date +%Y%m%d-%H%M%S` 获取时间戳
- 文件名：`{YYYYMMDD-HHMMSS}-{slug}.md`
- 完整路径：`.docforge/outbox/{filename}.md`

记录 `slug`（不含时间戳部分）供后续 `/ingest-remote` 使用。

#### 步骤 3.3：组装上报包

按以下模板组装，所有内容必须内联——外部 AI 无法访问本地文档：

```markdown
# Remote AI Request（主动上报）

> 生成时间：{YYYYMMDD-HHMMSS}
> 触发原因：hardness-classify 评估结果 {N}/12（{等级}）
> 主要原因：{最高分维度说明}

---

## 项目背景

**项目名称**：MaeDoc

{从 AGENTS.md §1 + docs/index.md 提取的项目简介，2-5句}

**文档树概览**：
{从 docs/index.md 提取的一级文档结构，或列出 docs/ 目录主要内容}

---

## 当前任务

{用户在本次会话中想要完成什么，当前处于哪个阶段}

---

## 具体问题

{question 的完整描述，尽量精确——这是外部 AI 需要回答的核心}

---

## 相关文档内容

{对每个相关文档：
### {文档标题}（{文档路径}）
{文档全文或关键章节，直接内联，不要只写"见附件"}}

---

## AI 的分析过程（为什么无法独立解决）

{ai_analysis：已考虑的角度、各方案的初步分析、卡住的地方、发现的矛盾}

---

## 已知约束

{从对话中提取的技术限制、用户偏好、明确排除项等}

---

## 期望输出

请提供一份**决策分析报告**，包含：

1. **问题诊断**：确认你理解问题的本质，指出关键决策点
2. **方案分析**：对各可能方案进行权衡（优势 / 劣势 / 适用条件）
3. **明确建议**：给出你的推荐方案，并说明推理依据
4. **风险提示**：指出推荐方案的主要风险和需要注意的事项
5. **后续步骤**：建议的下一步行动（如有）

请直接给出判断，避免"这取决于具体情况"式的模糊回答。
```

#### 步骤 3.4：写入文件

确保 `.docforge/outbox/` 目录存在，将上报包写入 `outbox_file`。

#### 步骤 3.5：告知用户

输出以下提示（简洁，不重复评估细节）：

```
已生成外部求助包：`.docforge/outbox/{filename}.md`

**下一步**：
1. 打开上述文件，复制全部内容
2. 粘贴到 Claude.ai / ChatGPT 等外部 AI，发送
3. 将外部 AI 的回答保存为 `.docforge/inbox/{filename}.md`
4. 运行 `/ingest-remote {slug}` 将建议应用到文档
```

---

## 错误处理

| 场景 | 处理方式 |
|------|---------|
| `docs/index.md` 不存在 | 跳过文档树概览，仅使用 AGENTS.md §1 的项目介绍 |
| 相关文档读取失败 | 在上报包中注明"文档读取失败：{路径}"，继续生成其余内容 |
| `date` 命令失败 | 使用占位时间戳 `00000000-000000` |
| `.docforge/outbox/` 不存在 | 自动创建，无需询问用户 |
| 上报包过长（超过 8000 字） | 在"相关文档内容"部分只保留关键章节（与问题最相关的段落），并注明已截断 |

---

## 流程图

```
调用 hardness-classify
    │
    ▼
[步骤 1] 六维评分 → 计算总分 → 确定等级
    │
    ▼
[步骤 2] 输出评估报告（2-4行）
    │
    ├─ LOW / MEDIUM → 返回正常回答流程
    │
    └─ HIGH
        │
        ▼
    [步骤 3] 收集上下文
        │ 项目背景 + 当前任务 + 相关文档全文 + AI分析 + 已知约束
        ▼
    [步骤 3.2] 生成文件名（时间戳 + slug）
        ▼
    [步骤 3.3] 组装上报包（自给自足，内联所有内容）
        ▼
    [步骤 3.4] 写入 .docforge/outbox/{filename}.md
        ▼
    [步骤 3.5] 告知用户路径与下一步操作
```
