# 开放问题：我还不知道答案的事

> **本文档定位**：记录思考过程中产生的、暂时无法回答的问题
> **所属系列**：[MaeDoc 设计反思与演进](../index.md)
> **相关文档**：[主动求助机制反思](../retrospect/design-reflections/proactive-escalation.md)

---

## 1. 为什么要记录「不知道」

探索性写作的一个核心原则是：**诚实面对不确定性**。

很多时候，我会假装自己知道答案，给出一些建议或方向。但有些问题，我真的不知道答案。把它们记录下来有两个好处：

1. **避免遗忘**：好问题比好答案更珍贵
2. **邀请协作**：如果你有想法，欢迎交流

---

## 2. 关于本地模型

### Q1: 本地模型 2 年后会进化到什么程度？

**背景**：

本地模型的发展速度很快。Llama 3.1 已经能在很多场景下表现不错，但距离「完全替代远程模型」还有差距。

**问题**：

- 2 年后，本地模型能做到什么程度？
- 如果本地模型足够强，MaeDoc 的「远程桥接」机制还需要吗？
- 我应该为「本地模型足够强」的未来做什么准备？

**我的猜测**：

本地模型会持续进步，但在「深度推理」和「专业知识」方面，可能仍然落后于顶级远程模型。远程桥接机制不会消失，但使用频率会下降。

---

### Q2: RAG 真的适合 MaeDoc 的场景吗？

**背景**：

RAG（检索增强生成）是增强 AI 能力的常见方案。但它是否适合「文档写作」场景？

**问题**：

- 文档写作需要的是「创造性」还是「准确性」？
- 如果是创造性，RAG 可能反而限制了 AI 的想象空间
- 如果是准确性，RAG 的检索精度足够吗？

**我的困惑**：

RAG 在「问答」场景效果很好，因为问题是明确的。但在「写作」场景，AI 需要综合多个来源、进行创造性组合，RAG 的效果不确定。

---

### Q3: 针对文档写作的微调有价值吗？

**背景**：

通用模型在文档写作方面已经表现不错。是否有必要进行专门的微调？

**问题**：

- 微调的数据从哪来？用户写作数据有隐私问题
- 微调后的模型会「过拟合」到特定写作风格吗？
- 微调的 ROI（投入产出比）如何评估？

**我的猜测**：

对于个人使用，微调的价值有限。除非有大量的、高质量的、标注过的写作数据，否则提示工程可能更高效。

---

## 3. 关于架构设计

### Q4: Skills 架构是否有更好的替代方案？

**背景**：

当前的 Skills 是「提示型」，每个 Skill 是一段 Markdown 文档，指导 AI 如何完成任务。

**问题**：

- 提示型 Skills 的表达能力有限，无法定义复杂的状态机
- 是否应该引入「代码型 Skills」，用代码定义更复杂的行为？
- 如果引入代码型 Skills，如何保持「可读性」和「可修改性」？

**我的困惑**：

提示型 Skills 的好处是「可读」和「易修改」，但能力有限。代码型 Skills 能力更强，但门槛更高。有没有两全的方案？

---

### Q5: 文档类型系统是否应该「回来」？

**背景**：

v0022 删除了模板系统，让 AI 自由判断结构。这带来了灵活性，但也降低了可预测性。

**问题**：

- 是否存在「半结构化」的中间形态？
- 「参考结构库」是一个好的方案吗？
- 用户是否真的需要「可预测的结构」？

**我的困惑**：

不同用户可能有不同偏好。有些用户希望「给我一个框架，我来填」，有些用户希望「我来说想法，你来组织」。如何同时满足这两种需求？

---

### Q6: 多文档树的「一致性」如何保证？

**背景**：

当文档以多文件形式组织时，保持各文件之间的一致性是一个挑战。

**已迈出的一步**：`doc-outline-generate` 和 `doc-content-fill` 现在会在执行前读取 `docs/index.md` 和相关文档，提取已有术语，避免重复内容。这是轻量级的一致性手段，不需要向量数据库。

**仍开放的问题**：

- 如何检测已有内容中的矛盾（而不只是避免重复）？
- 如何处理「内容漂移」（文档库逐渐偏离原始意图）？
- 长期是否需要引入 RAG 或专门的一致性检查工具？

---

## 4. 关于用户体验

### Q7: 交互式 vs 自动化的平衡点在哪里？

**背景**：

MaeDoc 采用「多轮交互」的设计，AI 会问用户问题来澄清意图。这保证了准确性，但也增加了交互成本。

**问题**：

- 用户愿意接受多少次交互？
- 什么时候应该「主动问」，什么时候应该「自己猜」？
- 如何让用户「跳过交互」但不影响结果质量？

**我的困惑**：

这是一个「用户信任」的问题。如果用户信任 AI，可以接受更少的交互。但信任需要时间建立。

---

### Q8: 如何让用户「发现」MaeDoc 的能力？

**背景**：

MaeDoc 有很多 Skills 和命令，但用户可能不知道它们的存在。

**问题**：

- 如何设计「能力发现」的机制？
- 是否需要「教程」或「引导」？
- 如何平衡「功能丰富」和「简单易用」？

**我的困惑**：

功能多了之后，用户往往会「只用最基本的功能」，高级功能被忽略。这是一个产品设计问题。

---

## 5. 关于未来方向

### Q9: MaeDoc 是否应该支持多人协作？

**背景**：

当前 MaeDoc 是为「个人使用」设计的。但文档写作往往是协作活动。

**问题**：

- 如果支持多人协作，需要哪些改动？
- 如何处理「版本冲突」？
- 如何保护隐私？

**我的猜测**：

短期内不会支持多人协作。这是一个大的架构变化，需要仔细设计。长期来看，这可能是「MaeDoc 2.0」的方向。

---

### Q10: 文档写作 Agent 的终局是什么？

**背景**：

MaeDoc 是「文档写作 AI Agent」。但 AI Agent 本身还在快速演进。

**问题**：

- 5 年后，文档写作 Agent 会变成什么样？
- MaeDoc 的设计理念是否还适用？
- 有没有可能被更大的平台「吃掉」？

**我的看法**：

这是一个开放问题，没有标准答案。但我倾向于认为：
- 「本地优先」和「隐私可控」会是长期需求
- AI Agent 的形态会持续演进，但「帮助人类更好地思考和表达」这个目标不变
- MaeDoc 需要持续演进，但核心价值不会变

---

## 6. 开放问题的价值

这些问题不是「待解决的任务」，而是「探索的方向」。

它们提醒我：
- **不要假装全知道**：承认无知是进步的开始
- **保持开放心态**：答案可能来自意想不到的地方
- **记录比遗忘好**：即使现在没答案，未来可能会有

如果你对这些问题有任何想法，欢迎交流。也许是你的一个建议，能帮我找到答案。

---

*本章最后更新：2026-02-21*
